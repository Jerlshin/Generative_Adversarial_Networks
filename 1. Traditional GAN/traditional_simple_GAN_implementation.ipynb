{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand-written digits generation using GAN with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6078f7be90>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm # Arabic word 'taqaddum'\n",
    "# provides a fast and extensible progress bar for loops and other iterable process. 'auto' module is used to automatically choose the appropriate tqdm implementation based on the environment\n",
    "from torchvision import transforms\n",
    "# for variouls data transformations on images \n",
    "from torchvision.datasets import MNIST # 60,000 dataset of handwritten digits \n",
    "from torchvision.utils import make_grid \n",
    "# used to create a grid of images from a collections of images, for visualization purposes\n",
    "from torch.utils.data import DataLoader\n",
    "# for loading and managing bataches of data for training NN. for large datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size) # view() to reshape the tensor\n",
    "    # detach from the computation graph to prevent any gradient calculations.\n",
    "    # move the tensor to cpu. the (-1, *size) reshapes the tensor with -1 (total number of elements), \n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5) # to arrange images in a grid. \n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())# to rearrange the dim of the tensor\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single layer/block for the generator's neural network. each block should have a linear transformation to map to another shape\n",
    "def get_generator_block(input_dim, output_dim): # scalar\n",
    "    # returns a generator neural network layer\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim), # fully connected layer, output_dim, is the no of units/neurons in the layer\n",
    "        nn.BatchNorm1d(num_features=output_dim ),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25, out_features=12, bias=True)\n",
       "  (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generator_block(25, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator:    \n",
    "* Noise vector dim\n",
    "* Image dim\n",
    "* Initial hidden dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherits from the base class nn.Module, we call super().__init__()initializer/constructor of the base class to properly initialize the inherited attirbutes and methods. \n",
    "class Generator(nn.Module): # to create a overall generator model\n",
    "    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128): \n",
    "        super(Generator, self).__init__() # used to access the parent class, nn.Module, by creating a reference to it through the 'super' function.\n",
    "        # Generator is the current class and self refers to the instance of the 'Generator class'\n",
    "        self.gen = nn.Sequential(   # sequential neural netowork\n",
    "            get_generator_block(z_dim, hidden_dim),\n",
    "            get_generator_block(hidden_dim, hidden_dim*2),\n",
    "            get_generator_block(hidden_dim*2, hidden_dim*4),\n",
    "            get_generator_block(hidden_dim*4, hidden_dim*8),\n",
    "            \n",
    "            #Dropdown\n",
    "            nn.Linear(hidden_dim*8, im_dim),\n",
    "            nn.Sigmoid()            \n",
    "        )\n",
    "    def forward(self, noise):  # forward pass of the model, with noise tensor\n",
    "        return self.gen(noise)\n",
    "\n",
    "    def get_gen(self):\n",
    "        return self.gen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n_samples, z_dim, device='cpu'): # samples , # dim of noise vector\n",
    "    return torch.randn(n_samples, z_dim, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator:\n",
    "\n",
    "We use Leaky ReLUs to prevent \"dying ReLU\" problem\n",
    "\n",
    "Phenomenon where the parameters stop changing due to consistently negative values passed to a ReLU, which result in zero gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disctiminator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.LeakyReLU(negative_slope=0.2),   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_dim=784, hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.disc = nn.Sequential(\n",
    "            get_disctiminator_block(im_dim, hidden_dim*4),\n",
    "            get_disctiminator_block(hidden_dim*4, hidden_dim*2),\n",
    "            get_disctiminator_block(hidden_dim*2, hidden_dim),\n",
    "            \n",
    "            nn.Linear(hidden_dim, 1) # output should be 1-D for Binary classification\n",
    "        )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        return self.disc(image)\n",
    "    \n",
    "    def get_disc(self): # by instance of the class itself\n",
    "        return self.disc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your parameters\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 200\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.00001\n",
    "\n",
    "# Load MNIST dataset as tensors\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "#device = 'cuda'\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the generator and discriminator and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device) # creating an instance and moving to the cuda\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)# optimizer of the gen.parameters()\n",
    "\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the discriminator's loss and generator's loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since generator is needed when calcualating the discriminator's loss, we do .detach() on gen result to ensure that only the discriminator is updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
    "    \n",
    "    # Create noise vectors and generate a batch (num_images) of fake_images\n",
    "    noise = get_noise(n_samples=num_images, z_dim=z_dim, device=device)\n",
    "    fake = gen(noise)\n",
    "    \n",
    "    # Get disc pred of fake images and calc the loss. --- Detach the generator. Ground truth of fake images is all zeros\n",
    "    disc_fake_pred = disc(fake.detach()) # dont update the param\n",
    "    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred, device=device))\n",
    "   \n",
    "    # Get the disc pred of the real image and calc the loss. One for real image\n",
    "    disc_real_pred = disc(real)\n",
    "    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred, device=device))\n",
    "     \n",
    "    # calc the disc loss by averaging the real and fake loss\n",
    "    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "    \n",
    "    return disc_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    \n",
    "    noise = get_noise(n_samples=num_images, z_dim=z_dim, device=device)\n",
    "    fake = gen(noise)\n",
    "    \n",
    "    disc_fake_pred = disc(fake)\n",
    "    \n",
    "    # calc the gen loss\n",
    "    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "    \n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Gen and Disc should grow equally. At first Disc will do better as it is easy to predict it is fake. If one model outperforms other, the training stops, so balance the two models.\n",
    "\n",
    "It is harder to do in Normal GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "test_generator = True \n",
    "gen_loss = False\n",
    "error = False\n",
    "for epoch in range(n_epochs):\n",
    "  \n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "\n",
    "        real = real.view(cur_batch_size, -1).to(device)\n",
    "\n",
    "        disc_opt.zero_grad()\n",
    "\n",
    "        # Calculate discriminator loss\n",
    "        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n",
    "\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "\n",
    "        disc_opt.step()\n",
    "\n",
    "        # For testing purposes, to keep track of the generator weights\n",
    "        if test_generator:\n",
    "            old_generator_weights = gen.gen[0][0].weight.detach().clone()\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "\n",
    "        # Calculate generator loss\n",
    "        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n",
    "\n",
    "        gen_loss.backward()\n",
    "\n",
    "        gen_opt.step()\n",
    "\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

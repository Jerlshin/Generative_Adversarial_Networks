{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate disentangled outputs <br>\n",
    "\n",
    "[InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](https://arxiv.org/abs/1606.03657)\n",
    "\n",
    "Mostly used method for disentanglement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3e70313a30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "   \n",
    "    def __init__(self, input_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(input_dim, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        \n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        \n",
    "        x = noise.view(len(noise), self.input_dim, 1, 1)\n",
    "        return self.gen(x)\n",
    "\n",
    "# for generating random noise\n",
    "def get_noise(n_samples, input_dim, device='cpu'):\n",
    "    \n",
    "    return torch.randn(n_samples, input_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, im_chan=1, hidden_dim=64, c_dim=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
    "        )\n",
    "        self.d_layer = self.make_disc_block(hidden_dim * 2, 1, final_layer=True)\n",
    "        self.q_layer = nn.Sequential(\n",
    "            self.make_disc_block(hidden_dim * 2, hidden_dim * 2),\n",
    "            self.make_disc_block(hidden_dim * 2, 2 * c_dim, kernel_size=1, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
    "       \n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        \n",
    "        intermediate_pred = self.disc(image)\n",
    "        disc_pred = self.d_layer(intermediate_pred)\n",
    "        q_pred = self.q_layer(intermediate_pred)\n",
    "        return disc_pred.view(len(disc_pred), -1), q_pred.view(len(q_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To combine the z and c vector to make the input to the model\n",
    "def combine_vectors(x, y):\n",
    "    combined = torch.cat([x.float(), y.float()], 1) # along dim 1\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize the images\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), nrow=5, show=True):\n",
    "\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_criterion = nn.BCEWithLogitsLoss() # adversarial loss\n",
    "c_criterion = lambda c_true, mean, logvar: Normal(mean, logvar.exp()).log_prob(c_true).mean()  # mutual information term for regularization - disentanglement\n",
    "c_lambda = 0.1 # weight on the c_criterion\n",
    "mnist_shape = (1, 28, 28)\n",
    "n_epochs = 80\n",
    "z_dim = 64 # dim of noise vector\n",
    "c_dim = 2 # dim of the InfoGAN latent code\n",
    "display_step = 500 # how often to display the images\n",
    "batch_size = 128 # no of images per forward/backward pass\n",
    "\n",
    "d_lr = 2e-4 # disc lr\n",
    "g_lr = 1e-3 # gen lr\n",
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(input_dim=z_dim + c_dim).to(device=device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=g_lr)\n",
    "\n",
    "disc = Discriminator(im_chan=mnist_shape[0], c_dim=c_dim).to(device=device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=d_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# initializing the weights\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        \n",
    "        # latent code\n",
    "        c_labels = get_noise(cur_batch_size, c_dim, device=device)\n",
    "        \n",
    "        ### Update Discriminator\n",
    "        disc_opt.zero_grad()\n",
    "        fake_noise = get_noise(cur_batch_size, z_dim, device=device) # getting the latent noise\n",
    "        noise_and_labels = combine_vectors(fake_noise, c_labels)\n",
    "        fake = gen(noise_and_labels)\n",
    "        \n",
    "        # Get disc predictions\n",
    "        disc_fake_pred, disc_q_pred = disc(fake.detach())\n",
    "        \n",
    "        disc_q_mean = disc_q_pred[:, :c_dim]\n",
    "        disc_q_logvar = disc_q_pred[:, c_dim:]\n",
    "        \n",
    "        mutual_information = c_criterion(c_labels, disc_q_mean, disc_q_logvar)\n",
    "        \n",
    "        disc_real_pred, _ = disc(real)\n",
    "        disc_fake_loss = adv_criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_loss = adv_criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "        \n",
    "        '''Disc loss'''\n",
    "        disc_loss = (disc_fake_loss + disc_real_loss) / 2 - c_lambda * mutual_information\n",
    "        disc_loss.backward(retain_graph = True)\n",
    "        disc_opt.step()\n",
    "        \n",
    "        discriminator_losses += [disc_loss.item()]\n",
    "        \n",
    "        ### Update generator\n",
    "        gen_opt.zero_grad()\n",
    "        \n",
    "\n",
    "        disc_fake_pred, disc_q_pred = disc(fake)\n",
    "        disc_q_mean = disc_q_pred[:, :c_dim]\n",
    "        disc_q_logvar = disc_q_pred[:, c_dim:]\n",
    "        mutual_information = c_criterion(c_labels, disc_q_mean, disc_q_logvar)\n",
    "        gen_loss = adv_criterion(disc_fake_pred, torch.ones_like(disc_fake_pred)) - c_lambda * mutual_information\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the generator losses\n",
    "        generator_losses += [gen_loss.item()]\n",
    "\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
    "            print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            step_bins = 20\n",
    "            x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Discriminator Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        cur_step += 1        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "n_interpolation = 9 # interpolation we want + 2(start and end_image)\n",
    "\n",
    "def interpolate_class(n_view=5):\n",
    "    interpolation_noise = get_noise(n_view, z_dim, device=device).repeat(n_interpolation, 1)\n",
    "    first_label = get_noise(1, c_dim).repeat(n_view, 1)[None, :]\n",
    "    second_label = first_label.clone()\n",
    "    first_label[:, :, 0] =  -2\n",
    "    second_label[:, :, 0] =  2\n",
    "    \n",
    "\n",
    "    # interpolation vector between the two labels\n",
    "    percent_second_label = torch.linspace(0, 1, n_interpolation)[:, None, None]\n",
    "    interpolation_labels = first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    interpolation_labels = interpolation_labels.view(-1, c_dim)\n",
    "\n",
    "    # Combining the noise and the labels\n",
    "    noise_and_labels = combine_vectors(interpolation_noise, interpolation_labels.to(device))\n",
    "    fake = gen(noise_and_labels)\n",
    "    show_tensor_images(fake, num_images=n_interpolation * n_view, nrow=n_view, show=False)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "interpolate_class()\n",
    "_ = plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
